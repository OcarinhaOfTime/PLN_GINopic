{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SCui0Afa9Z9g"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carrega o csv"
      ],
      "metadata": {
        "id": "7qiX47Sx_L87"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6gpYuGoa7eEQ"
      },
      "outputs": [],
      "source": [
        "file_path = 'files/pre-processed.csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divide o dataset em treinamento, validação e teste"
      ],
      "metadata": {
        "id": "pmfZljmVIxAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "PXF2zsDWImk6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adiciona a coluna 'partition' com as partições apropriadas"
      ],
      "metadata": {
        "id": "C5Sa5MqIJAmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['partition'] = 'training'\n",
        "val_df['partition'] = 'validation'\n",
        "test_df['partition'] = 'test'"
      ],
      "metadata": {
        "id": "kz8lBnSoIpTm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combina os dataframes"
      ],
      "metadata": {
        "id": "nQWLC9-JJKng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([train_df, val_df, test_df])"
      ],
      "metadata": {
        "id": "hfYJUtM6JOtb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria o arquivo .tsv"
      ],
      "metadata": {
        "id": "JpMJJffe_CqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_df = combined_df[['preprocessed_news', 'partition', 'label']]\n",
        "corpus_file_path = 'files/corpus.tsv'\n",
        "corpus_df.to_csv(corpus_file_path, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "id": "bnNTz1hx9WOP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extrai palavras únicas criando o vocabulário"
      ],
      "metadata": {
        "id": "YHWE3LEO-7R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "df['preprocessed_news'].str.split().apply(vocabulary.update)\n",
        "vocabulary_file_path = 'files/vocabulary.txt'\n",
        "with open(vocabulary_file_path, 'w') as vocab_file:\n",
        "    vocab_file.write('\\n'.join(sorted(vocabulary)))"
      ],
      "metadata": {
        "id": "jDPlVuhp-ynw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria o arquivo metadata.json"
      ],
      "metadata": {
        "id": "K_GAChlsYpIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "    \"total_documents\": len(df),\n",
        "    \"vocabulary_length\": len(vocabulary),\n",
        "    \"preprocessing-info\": [],\n",
        "    \"labels\": sorted(combined_df['label'].unique().tolist()),\n",
        "    \"total_labels\": combined_df['label'].nunique(),\n",
        "    \"last-training-doc\": int(train_df.index[-1]) + 1,\n",
        "    \"last-validation-doc\": int(val_df.index[-1]) + 1,\n",
        "}\n",
        "\n",
        "metadata_file_path = 'files/metadata.json'\n",
        "with open(metadata_file_path, 'w') as metadata_file:\n",
        "    json.dump(metadata, metadata_file, indent=4)"
      ],
      "metadata": {
        "id": "2Uo72DoOYb_X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carrega conjunto de dados pré-processado"
      ],
      "metadata": {
        "id": "y3ZtHUcBKCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from octis.dataset.dataset import Dataset\n",
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder('files')"
      ],
      "metadata": {
        "id": "k8wBCBVgE7dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptSTCf59FWuo",
        "outputId": "b83067a8-0a71-4704-bb15-15c9cdb1aad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<octis.dataset.dataset.Dataset object at 0x7d4177a49540>\n"
          ]
        }
      ]
    }
  ]
}