{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824878dd-3950-4a2a-a67d-f9c8d95f9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, sys, json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe06d2d-e147-4ec1-8ea9-c01df8485ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vagner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/vagner/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words_br = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe08c598-4b1b-42a6-8278-7c6fab6060c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_en(txt):\n",
    "    txt = txt.lower() #All to lower\n",
    "    txt = re.sub(r'\\W+', ' ', txt) #Remove special chars\n",
    "    tokens = word_tokenize(txt) #Tokenizing text\n",
    "    tokens = [w for w in tokens if w not in stop_words] # Removing stopwords    \n",
    "    tokens = [w for w in tokens if re.match(r'[a-z]+$', w) != None]\n",
    "    \n",
    "    txt = ' '.join(tokens)\n",
    "    if len(txt) == 0:\n",
    "        return None\n",
    "\n",
    "    return txt\n",
    "\n",
    "def pre_process_br(txt):\n",
    "    txt = txt.lower() #All to lower\n",
    "    txt = re.sub(r'\\W+', ' ', txt) #Remove special chars\n",
    "    tokens = word_tokenize(txt) #Tokenizing text\n",
    "    tokens = [w for w in tokens if w not in stop_words_br] # Removing stopwords    \n",
    "    tokens = [w for w in tokens if re.match(r'[a-z]+$', w) != None]\n",
    "    \n",
    "    txt = ' '.join(tokens)\n",
    "    if len(txt) == 0:\n",
    "        return None\n",
    "\n",
    "    return txt\n",
    "\n",
    "def train_test_val_split(df):\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.4, random_state=666)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=666)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739bbd97-e3c6-4602-aa10-021133ee4326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "data_dir = '../preprocessed_datasets'\n",
    "dataset_dir = f'{data_dir}/hotels_reviews'\n",
    "\n",
    "df = pd.read_csv(f'{dataset_dir}/Hotel_Reviews.csv')\n",
    "df_train, df_val, df_test = train_test_val_split(df)\n",
    "df_train['partition'] = 'train'\n",
    "df_val['partition'] = 'val'\n",
    "df_test['partition'] = 'test'\n",
    "\n",
    "# Combining\n",
    "combined_df = pd.concat([df_train, df_val, df_test])[['reviews.text', 'partition', 'reviews.rating']].dropna()\n",
    "combined_df['txt'] = combined_df['reviews.text'].apply(pre_process_en)\n",
    "combined_df['label'] = combined_df['reviews.rating'].apply(int)\n",
    "corpus_df = combined_df[['txt', 'partition', 'label']].dropna().reset_index(drop=True)\n",
    "labels = sorted(combined_df['label'].unique())\n",
    "\n",
    "#Saving\n",
    "corpus_df.to_csv(f'{dataset_dir}/corpus.tsv', sep='\\t', index=False, header=False)\n",
    "vocab = sorted({w for s in corpus_df.txt for w in s.split(' ')})\n",
    "open(f'{dataset_dir}/vocabulary.txt', 'w+').write('\\n'.join(vocab))\n",
    "\n",
    "metadata = {\n",
    "    \"total_documents\": len(corpus_df),\n",
    "    \"vocabulary_length\": len(vocab),\n",
    "    \"preprocessing-info\": [],\n",
    "    \"labels\": labels,\n",
    "    \"total_labels\": len(labels),\n",
    "    \"last-training-doc\": np.where(corpus_df.partition == 'train')[0][-1],\n",
    "    \"last-validation-doc\": np.where(corpus_df.partition == 'val')[0][-1]\n",
    "}\n",
    "meta_raw = json.dumps(metadata, cls=NpEncoder, indent=4)\n",
    "open(f'{dataset_dir}/metadata.json', 'w+').write(meta_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513a1303-fe87-47cb-aed9-6e6e2d133c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "      <td>katia abreu diz vai colocar expulsao moldura n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>ray peita bolsonaro conservador fake entrevist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fake</td>\n",
       "      <td>reinaldo azevedo desmascarado policia federal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fake</td>\n",
       "      <td>relatorio assustador bndes mostra dinheiro pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fake</td>\n",
       "      <td>radialista americano fala sobre pt vendem ilus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>true</td>\n",
       "      <td>cao acha drogas dentro fogao durante megaopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>true</td>\n",
       "      <td>determinacao diminuicao vazao represa caconde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>true</td>\n",
       "      <td>reforma previdencia governo pode suspender abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>true</td>\n",
       "      <td>zuckerberg diz facebook vai atuar garantir int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>true</td>\n",
       "      <td>negocios tras wellness nova moda agita mercado...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index label                                  preprocessed_news\n",
       "0         0  fake  katia abreu diz vai colocar expulsao moldura n...\n",
       "1         1  fake  ray peita bolsonaro conservador fake entrevist...\n",
       "2         2  fake  reinaldo azevedo desmascarado policia federal ...\n",
       "3         3  fake  relatorio assustador bndes mostra dinheiro pub...\n",
       "4         4  fake  radialista americano fala sobre pt vendem ilus...\n",
       "...     ...   ...                                                ...\n",
       "4995   4995  true  cao acha drogas dentro fogao durante megaopera...\n",
       "4996   4996  true  determinacao diminuicao vazao represa caconde ...\n",
       "4997   4997  true  reforma previdencia governo pode suspender abo...\n",
       "4998   4998  true  zuckerberg diz facebook vai atuar garantir int...\n",
       "4999   4999  true  negocios tras wellness nova moda agita mercado...\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "data_dir = '../preprocessed_datasets'\n",
    "dataset_dir = f'{data_dir}/BRNews'\n",
    "\n",
    "df = pd.read_csv(f'{dataset_dir}/pre-processed.csv').reset_index(drop=True)[:5000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75141c0f-1551-4a20-b70f-89fe4e91815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>partition</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gol pagara r mi acidente transformou area casa...</td>\n",
       "      <td>train</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apos demitida globo atriz desabafa golpe pense...</td>\n",
       "      <td>train</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suposto americano diz michael jackson assassin...</td>\n",
       "      <td>train</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>completar quatro anos operacao lava jato curit...</td>\n",
       "      <td>train</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>presidente senado renan calheiros afirmou nest...</td>\n",
       "      <td>train</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>farsa lewandowski ja sabia fatiamento impeachm...</td>\n",
       "      <td>test</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>imoveis senadores aecio zeze perrella bh sao a...</td>\n",
       "      <td>test</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>dilma nega recebeu r milhoes odebrecht diz vai...</td>\n",
       "      <td>test</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>juiz federal sergio moro operacao lava jato se...</td>\n",
       "      <td>test</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>protecionismo atual semelhancas disputas levar...</td>\n",
       "      <td>test</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt partition label\n",
       "0     gol pagara r mi acidente transformou area casa...     train  true\n",
       "1     apos demitida globo atriz desabafa golpe pense...     train  fake\n",
       "2     suposto americano diz michael jackson assassin...     train  fake\n",
       "3     completar quatro anos operacao lava jato curit...     train  true\n",
       "4     presidente senado renan calheiros afirmou nest...     train  true\n",
       "...                                                 ...       ...   ...\n",
       "4995  farsa lewandowski ja sabia fatiamento impeachm...      test  fake\n",
       "4996  imoveis senadores aecio zeze perrella bh sao a...      test  true\n",
       "4997  dilma nega recebeu r milhoes odebrecht diz vai...      test  fake\n",
       "4998  juiz federal sergio moro operacao lava jato se...      test  true\n",
       "4999  protecionismo atual semelhancas disputas levar...      test  true\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val, df_test = train_test_val_split(df)\n",
    "df_train['partition'] = 'train'\n",
    "df_val['partition'] = 'val'\n",
    "df_test['partition'] = 'test'\n",
    "\n",
    "# Combining\n",
    "combined_df = pd.concat([df_train, df_val, df_test])[['preprocessed_news', 'partition', 'label']].dropna()\n",
    "combined_df['txt'] = combined_df['preprocessed_news'].apply(pre_process)\n",
    "#combined_df['label'] = combined_df['reviews.rating'].apply(int)\n",
    "corpus_df = combined_df[['txt', 'partition', 'label']].dropna().reset_index(drop=True)\n",
    "labels = sorted(combined_df['label'].unique())\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93aa4ca4-ebbd-41f5-8871-e57d5934b974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving\n",
    "corpus_df.to_csv(f'{dataset_dir}/corpus.tsv', sep='\\t', index=False, header=False)\n",
    "vocab = sorted({w for s in corpus_df.txt for w in s.split(' ')})\n",
    "open(f'{dataset_dir}/vocabulary.txt', 'w+').write('\\n'.join(vocab))\n",
    "\n",
    "metadata = {\n",
    "    \"total_documents\": len(corpus_df),\n",
    "    \"vocabulary_length\": len(vocab),\n",
    "    \"preprocessing-info\": [],\n",
    "    \"labels\": labels,\n",
    "    \"total_labels\": len(labels),\n",
    "    \"last-training-doc\": np.where(corpus_df.partition == 'train')[0][-1],\n",
    "    \"last-validation-doc\": np.where(corpus_df.partition == 'val')[0][-1]\n",
    "}\n",
    "meta_raw = json.dumps(metadata, cls=NpEncoder, indent=4)\n",
    "open(f'{dataset_dir}/metadata.json', 'w+').write(meta_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ca854-49d4-4dd0-a125-4447be2d23fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
