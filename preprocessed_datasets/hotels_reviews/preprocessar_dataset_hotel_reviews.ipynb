{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Remove stopwords, pontuação e converte para minusculo"
      ],
      "metadata": {
        "id": "sC_goT1e0SPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def process_text(text):\n",
        "    if isinstance(text, str):\n",
        "      text = text.lower()\n",
        "      text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "      text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "      return text\n",
        "    else:\n",
        "      return ''\n",
        "\n",
        "\n",
        "df = pd.read_csv('files/Hotel_Reviews.csv')\n",
        "\n",
        "df['reviews.text'] = df['reviews.text'].apply(process_text)\n",
        "\n",
        "df.to_csv('Processed_Hotel_Reviews.csv', index=False)\n",
        "\n",
        "# df[['reviews.text']].to_csv('Processed_Hotel_Reviews.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjQ3qA8h0BmS",
        "outputId": "b11a4f57-392b-4575-9fa4-a0de1d631828"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SCui0Afa9Z9g"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carrega o csv"
      ],
      "metadata": {
        "id": "7qiX47Sx_L87"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "6gpYuGoa7eEQ"
      },
      "outputs": [],
      "source": [
        "file_path = 'files/Processed_Hotel_Reviews.csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divide o dataset em treinamento, validação e teste"
      ],
      "metadata": {
        "id": "pmfZljmVIxAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "PXF2zsDWImk6"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adiciona a coluna 'partition' com as partições apropriadas"
      ],
      "metadata": {
        "id": "C5Sa5MqIJAmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['partition'] = 'train'\n",
        "val_df['partition'] = 'val'\n",
        "test_df['partition'] = 'test'"
      ],
      "metadata": {
        "id": "kz8lBnSoIpTm"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combina os dataframes"
      ],
      "metadata": {
        "id": "nQWLC9-JJKng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([train_df, val_df, test_df])"
      ],
      "metadata": {
        "id": "hfYJUtM6JOtb"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria o arquivo .tsv"
      ],
      "metadata": {
        "id": "JpMJJffe_CqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_df = combined_df[['reviews.text', 'partition', 'reviews.rating']]\n",
        "corpus_file_path = 'files/corpus.tsv'\n",
        "corpus_df.to_csv(corpus_file_path, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "id": "bnNTz1hx9WOP"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extrai palavras únicas criando o vocabulário"
      ],
      "metadata": {
        "id": "YHWE3LEO-7R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "\n",
        "for review_text in df['reviews.text'].astype(str):\n",
        "    for word in review_text.split():\n",
        "        if word.isalpha():\n",
        "            vocabulary.add(word)\n",
        "\n",
        "vocabulary_file_path = 'files/vocabulary.txt'\n",
        "with open(vocabulary_file_path, 'w') as vocab_file:\n",
        "    vocab_file.write('\\n'.join(sorted(vocabulary)))"
      ],
      "metadata": {
        "id": "jDPlVuhp-ynw"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria o arquivo metadata.json"
      ],
      "metadata": {
        "id": "K_GAChlsYpIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "    \"total_documents\": len(df),\n",
        "    \"vocabulary_length\": len(vocabulary),\n",
        "    \"preprocessing-info\": [],\n",
        "    \"labels\": sorted(combined_df['reviews.rating'].unique().tolist()),\n",
        "    \"total_labels\": combined_df['reviews.rating'].nunique(),\n",
        "    \"last-training-doc\": int(train_df.index[-1]) + 1,\n",
        "    \"last-validation-doc\": int(val_df.index[-1]) + 1,\n",
        "}\n",
        "\n",
        "metadata_file_path = 'files/metadata.json'\n",
        "with open(metadata_file_path, 'w') as metadata_file:\n",
        "    json.dump(metadata, metadata_file, indent=4)"
      ],
      "metadata": {
        "id": "2Uo72DoOYb_X"
      },
      "execution_count": 142,
      "outputs": []
    }
  ]
}